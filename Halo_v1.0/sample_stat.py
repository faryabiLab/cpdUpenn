import sys

#This program takes in the following args
# 1) sample name
# 2) .stat files generated by samtools stat on sam file post alignment
# 3) .stat file generated by samtools stat on bam file post deduplication
# 4) .stat file generated by samtools stat on bam file prior to variant calls
# 5) .depth.sample_summary generated by GATK DepthOfCoverage tool on bam file prior to variant calls
# 6) .depth.sample_interval_summary generated by GATK DepthOfCoverage tool on bam file prior to variant calls
def alignment_metrics(stat):
    with open (stat, 'r') as stat_in:
        for line in stat_in:
                if 'QC-passed reads + QC-failed reads' in line:
                    alignments = line.split('+')
                    total = alignments[0]
                elif 'mapped (' in line:
                    alignments = line.split('+')
                    mapped = alignments[0]
                elif 'itself and mate mapped' in line:
                    alignments = line.split('+')
                    aligned = alignments[0]
        return {'total':total, 'mapped':mapped, 'aligned':aligned}


def depth_cumulative(sample_name, depth_sum):
      with open (depth_sum,'r') as depth_in:
          for line in depth_in:
              if sample_name in line:
                  line = line.rstrip()
                  depth_summary = line.split('\t')
                  mean = depth_summary[2]
                  above_0 = depth_summary[6]
                  above_1 = depth_summary[7]
                  above_150 = depth_summary[8]
                  above_250 = depth_summary[9]
                  above_1000 = depth_summary[10]
      return {'mean':mean, 'above_0':above_0, 'above_1':above_1, 'above_150':above_150, 'above_250':above_250, 'above_1000':above_1000}

def depth_interval_stats(depth_stat):
    with open (depth_stat, 'r') as stat_in:
           exons_below_150 = 0
           exons_below_250 = 0
           for line in stat_in:
               line = line.rstrip()
               if 'chr' in line:
                   interval_stat = line.split('\t')
                   mean_interval_cvg = interval_stat[4]
                   if float(mean_interval_cvg) < 150:
                       exons_below_150 += 1 
                   if float(mean_interval_cvg) < 250:
                       exons_below_250 += 1
    return {'exons_below_150':exons_below_150, 'exons_below_250':exons_below_250}

def create_stats(sample_name, post_align, post_dedup, post_filter, depth_summary, interval_stats, stats_out):
    stats_file = stats_out
    with open (stats_file, 'w+') as stats_f:
        stats_f.write('#SampleName\tTotalStartingReads\tTotalReadsInputForAlignment\tPercantageLost\tReadsMapped\tPercentageReadMapping\tTotalOnTarget\tPercentageOnTarget\t' +
                         'TotalOnTargetFilterReads\tPercentageOnTargetFilter\tPercentageUsable\tMeanCoverage\tPercentBases_above_0\tPercentBases_above_1\tPercentBases_above_250\t' +
                         'PercentBases_above_1000\tNo._of_amplicons(exonic_part)_below_250x\tClipCount\tNo._of_amplicons(exonic_part)_below_150x\n')
        post_align_stat = alignment_metrics(post_align)
        post_dedup_stat = alignment_metrics(post_dedup)
        post_filter_stat = alignment_metrics(post_filter)
        
        #alignment Percentages
        aligned = float(post_align_stat['aligned'])/float(post_align_stat['total']) * 100
        total_loss = ((float(post_align_stat['total']) - float(post_align_stat['aligned']))/float(post_align_stat['total']) * 100)
        duplicates = float(post_dedup_stat['aligned'])/float(post_align_stat['aligned']) * 100
        filtered = float(post_filter_stat['aligned'])/float(post_dedup_stat['aligned']) * 100
        usable = float(post_filter_stat['aligned'])/float(post_align_stat['total']) * 100
        
        depth_stat = depth_cumulative(sample_name,depth_summary)
        interval_stat_sum = depth_interval_stats(interval_stats)

        
        stats_f.write(sample_name + '\t' + post_align_stat['total'] + '\t' + post_align_stat['aligned'] + '\t' + "{0:.2f}".format(total_loss) + '\t' + 
                     post_align_stat['aligned'] + '\t' + "{0:.2f}".format(aligned) + '\t' + post_dedup_stat['aligned'] + '\t' + "{0:.2f}".format(duplicates) + '\t' + 
                     post_filter_stat['aligned'] + '\t' + "{0:.2f}".format(filtered) + '\t' + "{0:.2f}".format(usable) + '\t' + depth_stat['mean'] + '\t' + 
                     depth_stat['above_0'] + '\t' + depth_stat['above_1'] + '\t' + depth_stat['above_250'] + '\t' + depth_stat['above_1000'] + '\t' + 
                     str(interval_stat_sum['exons_below_250']) + '\tNA\t' + str(interval_stat_sum['exons_below_150']) + '\n')
def main ():
    sample_name = sys.argv[1]
    post_align = sys.argv[2]
    post_dedup = sys.argv[3]
    post_filter = sys.argv[4]
    depth_summary = sys.argv[5]
    interval_stats = sys.argv[6]
    stats_out = sys.argv[7]
    create_stats(sample_name, post_align, post_dedup, post_filter, depth_summary, interval_stats,stats_out)
main()
